<?xml version="1.0" encoding="UTF-8"?>
<!--Autogenerated by Cloudera Manager-->
<configuration>
    <property>
        <name>fs.defaultFS</name>
        <value>hdfs://nameservice1</value>
    </property>

    <property>
        <name>dfs.nameservices</name>
        <value>nameservice1</value>
    </property>
    <property>
        <name>dfs.client.failover.proxy.provider.nameservice1</name>
        <value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
    </property>
    <property>
        <name>dfs.ha.automatic-failover.enabled.nameservice1</name>
        <value>true</value>
    </property>
    <property>
        <name>ha.zookeeper.quorum</name>
        <value>hadoop-test-dn1-9-13:2181,hadoop-test-nn1-9-11:2181,hadoop-test-nn2-9-12:2181</value>
    </property>
    <property>
        <name>dfs.ha.namenodes.nameservice1</name>
        <value>namenode230,namenode244</value>
    </property>
    <property>
        <name>dfs.namenode.rpc-address.nameservice1.namenode230</name>
        <value>hadoop-test-nn1-9-11:8020</value>
    </property>
    <property>
        <name>dfs.namenode.servicerpc-address.nameservice1.namenode230</name>
        <value>hadoop-test-nn1-9-11:8022</value>
    </property>
    <property>
        <name>dfs.namenode.http-address.nameservice1.namenode230</name>
        <value>hadoop-test-nn1-9-11:50070</value>
    </property>
    <property>
        <name>dfs.namenode.https-address.nameservice1.namenode230</name>
        <value>hadoop-test-nn1-9-11:50470</value>
    </property>
    <property>
        <name>dfs.namenode.rpc-address.nameservice1.namenode244</name>
        <value>hadoop-test-nn2-9-12:8020</value>
    </property>
    <property>
        <name>dfs.namenode.servicerpc-address.nameservice1.namenode244</name>
        <value>hadoop-test-nn2-9-12:8022</value>
    </property>
    <property>
        <name>dfs.namenode.http-address.nameservice1.namenode244</name>
        <value>hadoop-test-nn2-9-12:50070</value>
    </property>
    <property>
        <name>dfs.namenode.https-address.nameservice1.namenode244</name>
        <value>hadoop-test-nn2-9-12:50470</value>
    </property>
    <property>
        <name>dfs.replication</name>
        <value>3</value>
    </property>
    <property>
        <name>dfs.blocksize</name>
        <value>134217728</value>
    </property>
    <property>
        <name>dfs.client.use.datanode.hostname</name>
        <value>false</value>
    </property>
    <property>
        <name>fs.permissions.umask-mode</name>
        <value>022</value>
    </property>
    <property>
        <name>dfs.encrypt.data.transfer.algorithm</name>
        <value>3des</value>
    </property>
    <property>
        <name>dfs.encrypt.data.transfer.cipher.suites</name>
        <value>AES/CTR/NoPadding</value>
    </property>
    <property>
        <name>dfs.encrypt.data.transfer.cipher.key.bitlength</name>
        <value>256</value>
    </property>
    <property>
        <name>dfs.namenode.acls.enabled</name>
        <value>false</value>
    </property>
    <property>
        <name>dfs.client.use.legacy.blockreader</name>
        <value>false</value>
    </property>
    <property>
        <name>dfs.client.read.shortcircuit</name>
        <value>false</value>
    </property>
    <property>
        <name>dfs.domain.socket.path</name>
        <value>/var/run/hdfs-sockets/dn</value>
    </property>
    <property>
        <name>dfs.client.read.shortcircuit.skip.checksum</name>
        <value>false</value>
    </property>
    <property>
        <name>dfs.client.domain.socket.data.traffic</name>
        <value>false</value>
    </property>
    <property>
        <name>dfs.datanode.hdfs-blocks-metadata.enabled</name>
        <value>true</value>
    </property>
    <property>
        <name>dfs.block.access.token.enable</name>
        <value>true</value>
    </property>
    <property>
        <name>dfs.namenode.kerberos.principal</name>
        <value>hdfs/_HOST@DZTECH.COM</value>
    </property>
    <property>
        <name>dfs.namenode.kerberos.internal.spnego.principal</name>
        <value>HTTP/_HOST@DZTECH.COM</value>
    </property>
    <property>
        <name>dfs.datanode.kerberos.principal</name>
        <value>hdfs/_HOST@DZTECH.COM</value>
    </property>

    <!-- 添加配置 -->
    <property>
        <name>fs.hdfs.impl.disable.cache</name>
        <value>true</value>
    </property>
    <property>
        <name>dfs.image.transfer.timeout</name>
        <value>1200000</value>
    </property>

    <property>
        <name>parquet.metadata.read.parallelism</name>
        <value>4</value>
    </property>
    <property>
        <name>parquet.compression</name>
        <value>SNAPPY</value>
    </property>

    <property>
        <name>io.file.buffer.size</name>
        <value>65536</value>
    </property>

    <property>
        <name>hadoop.security.authentication</name>
        <value>kerberos</value>
    </property>
    <property>
        <name>hadoop.security.authorization</name>
        <value>true</value>
    </property>
    <property>
        <name>hadoop.rpc.protection</name>
        <value>authentication</value>
    </property>

    <!-- hive config -->
    <property>
        <name>hive.metastore.warehouse.dir</name>
        <value>/user/hive/warehouse/</value>
    </property>
</configuration>